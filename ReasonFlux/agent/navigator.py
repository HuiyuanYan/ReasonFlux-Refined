import json
from ast import literal_eval
from typing import List, Dict
from ReasonFlux.agent.base import BaseAgent
from ReasonFlux.prompts.navigator import (
    TRAJECTORY_BUILDING_PROMPT,
    TRAJECTORY_ADJUST_PROMPT,
    REASONING_FLOW_UPDATE_PROMPT,
    INITIALIZE_REASON_PROBLEM_PROMPT
)
from ReasonFlux.agent.parser import think_answer_parser, json_parser

from pydantic import Field
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_core.runnables import RunnableSerializable

class Navigator(BaseAgent):
    """
    A class for navigating and controlling the reasoning process of a language model.

    This class is responsible for initializing the reasoning trajectory, guiding the model
    through different reasoning steps, and dynamically adjusting the reasoning flow.
    It maintains the reasoning thoughts, flow, and instructions generated by the model.

    Attributes:
        name (str): Name of the agent.
        description (str): Description of the agent's purpose.
        reasoning_thoughts (List): A list of reasoning thoughts generated by the model.
        reasoning_flow (List): A list of reasoning flows generated by the model.
        instantiation (List): A list of instantiation steps generated by the model.
        reasoning_rounds (int): The number of reasoning rounds completed by the model.
        reasoning_instructions (List): A list of reasoning instructions generated by the model.
        template (Dict): The template used for reasoning.
    """

    name: str = "Navigator"
    description: str = """A class for navigating and controlling the reasoning process of a language model.
    This class is responsible for initializing the reasoning trajectory, guiding the model
    through different reasoning steps, and dynamically adjusting the reasoning flow."""

    reasoning_thoughts: List = Field(
        default_factory=list,
        description="A list of reasoning thoughts generated by the model.",
    )

    reasoning_flow: List = Field(
        default_factory=list,
        description="A list of reasoning flows generated by the model.",
    )

    instantiation: List = Field(
        default_factory=list,
        description="A list of instantiation steps generated by the model.",
    )

    reasoning_rounds: int = Field(
        default=0,
        description="The number of reasoning rounds completed by the model.",
    )

    reasoning_instructions: List = Field(
        default_factory=list,
        description="A list of reasoning instructions generated by the model.",
    )

    template: Dict = Field(
        default=None,
        description="The template used for reasoning.",
    )

    def step(self, chain: RunnableSerializable, **kwargs):
        return chain.invoke(kwargs)

    def initializing_reasoning_trajectory(
        self,
        problem:str
    ) -> None:
        """
        Initializes the reasoning trajectory by generating a template from the language model.

        This method constructs a prompt to build the reasoning trajectory and runs it through
        the model client. It parses the response to update the reasoning flow and thoughts.

        Args:
            problem (str): The problem description.

        Returns:
            str: The thoughts generated for building the template.
        """

        prompt = TRAJECTORY_BUILDING_PROMPT

        chain = prompt | self.model_client | think_answer_parser


        res = self.run(chain, problem=problem)
        thoughts_for_template_building,template_str= res['thought'], res['answer']
        
        self.template = json_parser.parse(template_str)
        self.reasoning_thoughts.append(thoughts_for_template_building)
        self.reasoning_flow = self.template['reason_flow']
        self.reasoning_rounds = len(self.reasoning_flow)
    
    def dynamic_adjustment(
        self,
        trajectory: List[Dict], 
        retrieved_template: Dict
    ) -> str:
        """
        Dynamically adjusts the reasoning flow based on the provided trajectory and template.

        This method constructs a prompt to adjust the reasoning trajectory and runs it through
        the model client. It returns the new reasoning flow as a string.

        Args:
            trajectory (List[Dict]): The current reasoning trajectory.
            retrieved_template (Dict): The retrieved template for adjustment.

        Returns:
            str: The new reasoning flow as a string.
        """
        prompt = TRAJECTORY_ADJUST_PROMPT

        chain = prompt | self.model_client | think_answer_parser

        new_reasoning_flow = self.run(
            chain,
            original_reason_flow=json.dumps(trajectory, indent=2),
            standard_solution_template=json.dumps(retrieved_template, indent=2)
        )["answer"]

        return new_reasoning_flow
        # here we decouple the two operations
        # self.update_reasoning_flow(new_reasoning_flow)
    

    def update_reasoning_flow(
        self,
        reasoning_flow_str: str,
    ) -> None:
        """
        Updates the reasoning flow based on the retrieved template.

        This method constructs a prompt to update the reasoning flow and runs it through
        the model client. It parses the response to update the reasoning flow and rounds.

        Args:
            reasoning_flow_str (str): The new reasoning flow as a string.
        """
        prompt = REASONING_FLOW_UPDATE_PROMPT

        chain = prompt | self.model_client | json_parser

        updated_reasoning_flow = self.run(
            chain=chain,
            reasoning_flow=reasoning_flow_str
        )

        self.reasoning_flow = updated_reasoning_flow
        self.reasoning_rounds = len(self.reasoning_flow)
        self.template["reason_flow"] = self.reasoning_flow
    
    def initialize_reason_problem(self, problem, reason_step):
        """
        Initializes the reasoning problem by constructing a prompt based on the current reasoning state.

        This method constructs a prompt to initialize the reasoning problem and runs it through
        the model client. It returns the response text.

        Args:
            problem: The problem description.
            reason_step: The current reasoning step.

        Returns:
            str: The response text from the model.
        """
        system_prompt = INITIALIZE_REASON_PROBLEM_PROMPT

        histoty = []
        for i in range(len(self.reasoning_instructions)):
            histoty.append(
                SystemMessage(content=f"Current step: Step{i+1}:\n{self.reasoning_flow[i]}")
            )
            histoty.append(
                AIMessage(content=f"Step {i+1}:\n{self.reasoning_instructions[i]}", source= "assistant")
            )
            histoty.append(
                HumanMessage(content=f"Student Response for Step {i+1}:\n{self.instantiation[i]}")
            )
        
        continue_prompt = "Now based on the student's response and the previous steps, please continue to instruct students to implement this step."
        histoty.append(SystemMessage(content=f"{continue_prompt}\nCurrent step: Step {len(self.reasoning_instructions)+1}:\n{reason_step}"))
        
        prompt = system_prompt.__add__(
            ChatPromptTemplate.from_messages(histoty)
        )

        chain = prompt | self.model_client

        return self.run(chain=chain,problem=problem).text()
